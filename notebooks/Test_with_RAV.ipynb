{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c19fcb",
   "metadata": {},
   "source": [
    "## Test with Regression Activation Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862741f",
   "metadata": {},
   "source": [
    "In this notebook we calculate the sensitivity score and the Br score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c632dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import zipfile\n",
    "import tarfile\n",
    "import urllib\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import h5py as h5\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c8fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot\n",
    "import vector\n",
    "vector.register_awkward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a67ff99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billyli/miniforge_x86_new/envs/weaver/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b911319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from weaver.utils.dataset import SimpleIterDataset\n",
    "from weaver.train import test_load, model_setup\n",
    "from weaver.utils.logger import _logger, _configLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f78441",
   "metadata": {},
   "source": [
    "## Mimic Args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8dd62",
   "metadata": {},
   "source": [
    "Copied from train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdad2a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--hidden-states'], dest='hidden_states', nargs=0, const=True, default=False, type=None, choices=None, help='let ParT output hidden states with the logits', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regression-mode', action='store_true', default=False,\n",
    "                    help='run in regression mode if this flag is set; otherwise run in classification mode')\n",
    "parser.add_argument('-c', '--data-config', type=str,\n",
    "                    help='data config YAML file')\n",
    "parser.add_argument('--extra-selection', type=str, default=None,\n",
    "                    help='Additional selection requirement, will modify `selection` to `(selection) & (extra)` on-the-fly')\n",
    "parser.add_argument('--extra-test-selection', type=str, default=None,\n",
    "                    help='Additional test-time selection requirement, will modify `test_time_selection` to `(test_time_selection) & (extra)` on-the-fly')\n",
    "parser.add_argument('-i', '--data-train', nargs='*', default=[],\n",
    "                    help='training files; supported syntax:'\n",
    "                         ' (a) plain list, `--data-train /path/to/a/* /path/to/b/*`;'\n",
    "                         ' (b) (named) groups [Recommended], `--data-train a:/path/to/a/* b:/path/to/b/*`,'\n",
    "                         ' the file splitting (for each dataloader worker) will be performed per group,'\n",
    "                         ' and then mixed together, to ensure a uniform mixing from all groups for each worker.'\n",
    "                    )\n",
    "parser.add_argument('-l', '--data-val', nargs='*', default=[],\n",
    "                    help='validation files; when not set, will use training files and split by `--train-val-split`')\n",
    "parser.add_argument('-t', '--data-test', nargs='*', default=[],\n",
    "                    help='testing files; supported syntax:'\n",
    "                         ' (a) plain list, `--data-test /path/to/a/* /path/to/b/*`;'\n",
    "                         ' (b) keyword-based, `--data-test a:/path/to/a/* b:/path/to/b/*`, will produce output_a, output_b;'\n",
    "                         ' (c) split output per N input files, `--data-test a%%10:/path/to/a/*`, will split per 10 input files')\n",
    "parser.add_argument('--data-fraction', type=float, default=1,\n",
    "                    help='fraction of events to load from each file; for training, the events are randomly selected for each epoch')\n",
    "parser.add_argument('--file-fraction', type=float, default=1,\n",
    "                    help='fraction of files to load; for training, the files are randomly selected for each epoch')\n",
    "parser.add_argument('--fetch-by-files', action='store_true', default=False,\n",
    "                    help='When enabled, will load all events from a small number (set by ``--fetch-step``) of files for each data fetching. '\n",
    "                         'Otherwise (default), load a small fraction of events from all files each time, which helps reduce variations in the sample composition.')\n",
    "parser.add_argument('--fetch-step', type=float, default=0.01,\n",
    "                    help='fraction of events to load each time from every file (when ``--fetch-by-files`` is disabled); '\n",
    "                         'Or: number of files to load each time (when ``--fetch-by-files`` is enabled). Shuffling & sampling is done within these events, so set a large enough value.')\n",
    "parser.add_argument('--in-memory', action='store_true', default=False,\n",
    "                    help='load the whole dataset (and perform the preprocessing) only once and keep it in memory for the entire run')\n",
    "parser.add_argument('--train-val-split', type=float, default=0.8,\n",
    "                    help='training/validation split fraction')\n",
    "parser.add_argument('--no-remake-weights', action='store_true', default=False,\n",
    "                    help='do not remake weights for sampling (reweighting), use existing ones in the previous auto-generated data config YAML file')\n",
    "parser.add_argument('--demo', action='store_true', default=False,\n",
    "                    help='quickly test the setup by running over only a small number of events')\n",
    "parser.add_argument('--lr-finder', type=str, default=None,\n",
    "                    help='run learning rate finder instead of the actual training; format: ``start_lr, end_lr, num_iters``')\n",
    "parser.add_argument('--tensorboard', type=str, default=None,\n",
    "                    help='create a tensorboard summary writer with the given comment')\n",
    "parser.add_argument('--tensorboard-custom-fn', type=str, default=None,\n",
    "                    help='the path of the python script containing a user-specified function `get_tensorboard_custom_fn`, '\n",
    "                         'to display custom information per mini-batch or per epoch, during the training, validation or test.')\n",
    "parser.add_argument('-n', '--network-config', type=str,\n",
    "                    help='network architecture configuration file; the path must be relative to the current dir')\n",
    "parser.add_argument('-o', '--network-option', nargs=2, action='append', default=[],\n",
    "                    help='options to pass to the model class constructor, e.g., `--network-option use_counts False`')\n",
    "parser.add_argument('-m', '--model-prefix', type=str, default='models/{auto}/network',\n",
    "                    help='path to save or load the model; for training, this will be used as a prefix, so model snapshots '\n",
    "                         'will saved to `{model_prefix}_epoch-%%d_state.pt` after each epoch, and the one with the best '\n",
    "                         'validation metric to `{model_prefix}_best_epoch_state.pt`; for testing, this should be the full path '\n",
    "                         'including the suffix, otherwise the one with the best validation metric will be used; '\n",
    "                         'for training, `{auto}` can be used as part of the path to auto-generate a name, '\n",
    "                         'based on the timestamp and network configuration')\n",
    "parser.add_argument('--load-model-weights', type=str, default=None,\n",
    "                    help='initialize model with pre-trained weights')\n",
    "parser.add_argument('--exclude-model-weights', type=str, default=None,\n",
    "                    help='comma-separated regex to exclude matched weights from being loaded, e.g., `a.fc..+,b.fc..+`')\n",
    "parser.add_argument('--freeze-model-weights', type=str, default=None,\n",
    "                    help='comma-separated regex to freeze matched weights from being updated in the training, e.g., `a.fc..+,b.fc..+`')\n",
    "parser.add_argument('--num-epochs', type=int, default=20,\n",
    "                    help='number of epochs')\n",
    "parser.add_argument('--steps-per-epoch', type=int, default=None,\n",
    "                    help='number of steps (iterations) per epochs; '\n",
    "                         'if neither of `--steps-per-epoch` or `--samples-per-epoch` is set, each epoch will run over all loaded samples')\n",
    "parser.add_argument('--steps-per-epoch-val', type=int, default=None,\n",
    "                    help='number of steps (iterations) per epochs for validation; '\n",
    "                         'if neither of `--steps-per-epoch-val` or `--samples-per-epoch-val` is set, each epoch will run over all loaded samples')\n",
    "parser.add_argument('--samples-per-epoch', type=int, default=None,\n",
    "                    help='number of samples per epochs; '\n",
    "                         'if neither of `--steps-per-epoch` or `--samples-per-epoch` is set, each epoch will run over all loaded samples')\n",
    "parser.add_argument('--samples-per-epoch-val', type=int, default=None,\n",
    "                    help='number of samples per epochs for validation; '\n",
    "                         'if neither of `--steps-per-epoch-val` or `--samples-per-epoch-val` is set, each epoch will run over all loaded samples')\n",
    "parser.add_argument('--optimizer', type=str, default='ranger', choices=['adam', 'adamW', 'radam', 'ranger'],  # TODO: add more\n",
    "                    help='optimizer for the training')\n",
    "parser.add_argument('--optimizer-option', nargs=2, action='append', default=[],\n",
    "                    help='options to pass to the optimizer class constructor, e.g., `--optimizer-option weight_decay 1e-4`')\n",
    "parser.add_argument('--lr-scheduler', type=str, default='flat+decay',\n",
    "                    choices=['none', 'steps', 'flat+decay', 'flat+linear', 'flat+cos', 'one-cycle'],\n",
    "                    help='learning rate scheduler')\n",
    "parser.add_argument('--warmup-steps', type=int, default=0,\n",
    "                    help='number of warm-up steps, only valid for `flat+linear` and `flat+cos` lr schedulers')\n",
    "parser.add_argument('--load-epoch', type=int, default=None,\n",
    "                    help='used to resume interrupted training, load model and optimizer state saved in the `epoch-%%d_state.pt` and `epoch-%%d_optimizer.pt` files')\n",
    "parser.add_argument('--start-lr', type=float, default=5e-3,\n",
    "                    help='start learning rate')\n",
    "parser.add_argument('--batch-size', type=int, default=128,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--use-amp', action='store_true', default=False,\n",
    "                    help='use mixed precision training (fp16)')\n",
    "parser.add_argument('--gpus', type=str, default='0',\n",
    "                    help='device for the training/testing; to use CPU, set to empty string (\"\"); to use multiple gpu, set it as a comma separated list, e.g., `1,2,3,4`')\n",
    "parser.add_argument('--predict-gpus', type=str, default=None,\n",
    "                    help='device for the testing; to use CPU, set to empty string (\"\"); to use multiple gpu, set it as a comma separated list, e.g., `1,2,3,4`; if not set, use the same as `--gpus`')\n",
    "parser.add_argument('--num-workers', type=int, default=1,\n",
    "                    help='number of threads to load the dataset; memory consumption and disk access load increases (~linearly) with this numbers')\n",
    "parser.add_argument('--predict', action='store_true', default=False,\n",
    "                    help='run prediction instead of training')\n",
    "parser.add_argument('--predict-output', type=str,\n",
    "                    help='path to save the prediction output, support `.root` and `.parquet` format')\n",
    "parser.add_argument('--export-onnx', type=str, default=None,\n",
    "                    help='export the PyTorch model to ONNX model and save it at the given path (path must ends w/ .onnx); '\n",
    "                         'needs to set `--data-config`, `--network-config`, and `--model-prefix` (requires the full model path)')\n",
    "parser.add_argument('--onnx-opset', type=int, default=15,\n",
    "                    help='ONNX opset version.')\n",
    "parser.add_argument('--io-test', action='store_true', default=False,\n",
    "                    help='test throughput of the dataloader')\n",
    "parser.add_argument('--copy-inputs', action='store_true', default=False,\n",
    "                    help='copy input files to the current dir (can help to speed up dataloading when running over remote files, e.g., from EOS)')\n",
    "parser.add_argument('--log', type=str, default='',\n",
    "                    help='path to the log file; `{auto}` can be used as part of the path to auto-generate a name, based on the timestamp and network configuration')\n",
    "parser.add_argument('--print', action='store_true', default=False,\n",
    "                    help='do not run training/prediction but only print model information, e.g., FLOPs and number of parameters of a model')\n",
    "parser.add_argument('--profile', action='store_true', default=False,\n",
    "                    help='run the profiler')\n",
    "parser.add_argument('--backend', type=str, choices=['gloo', 'nccl', 'mpi'], default=None,\n",
    "                    help='backend for distributed training')\n",
    "parser.add_argument('--cross-validation', type=str, default=None,\n",
    "                    help='enable k-fold cross validation; input format: `variable_name%%k`')\n",
    "parser.add_argument('--disable-mps', action='store_true', default=False,\n",
    "                    help='disable using mps device if it does not work for you')\n",
    "parser.add_argument('--hidden-states-out', type=str, default=\"hidden_states_out.h5\",\n",
    "                    help='path to save hidden states as h5 file')\n",
    "parser.add_argument('--hidden-states', action='store_true', default=False,\n",
    "                    help='let ParT output hidden states with the logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0760cfa",
   "metadata": {},
   "source": [
    "manually parse args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bd4ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(backend=None, batch_size=128, copy_inputs=False, cross_validation=None, data_config='/Users/billyli/scope/particle_transformer/data/JetClass/JetClass_full.yaml', data_fraction=0.001, data_test=['/Users/billyli/scope/JetClass/minimal/*.root'], data_train=[], data_val=[], demo=False, disable_mps=True, exclude_model_weights=None, export_onnx=None, extra_selection=None, extra_test_selection=None, fetch_by_files=False, fetch_step=0.01, file_fraction=1, freeze_model_weights=None, gpus='', hidden_states=True, hidden_states_out='hidden_states_out.h5', in_memory=False, io_test=False, load_epoch=None, load_model_weights=None, log='', lr_finder=None, lr_scheduler='flat+decay', model_prefix='/Users/billyli/scope/particle_transformer/models/ParT_full.pt', network_config='/Users/billyli/scope/particle_transformer/networks/ParT_w_hidden_states.py', network_option=[], no_remake_weights=False, num_epochs=20, num_workers=0, onnx_opset=15, optimizer='ranger', optimizer_option=[], predict=True, predict_gpus=None, predict_output='/Users/billyli/scope/particle_transformer/tmp/test_output.root', print=False, profile=False, regression_mode=False, samples_per_epoch=None, samples_per_epoch_val=None, start_lr=0.005, steps_per_epoch=None, steps_per_epoch_val=None, tensorboard=None, tensorboard_custom_fn=None, train_val_split=0.8, use_amp=True, warmup_steps=0)\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args([\n",
    "    \"--predict\",\n",
    "    \"--data-test\", \"/Users/billyli/scope/JetClass/minimal/*.root\",\n",
    "    \"--data-config\", \"/Users/billyli/scope/particle_transformer/data/JetClass/JetClass_full.yaml\",\n",
    "    \"--data-fraction\", \"0.001\",\n",
    "    \"--network-config\", \"/Users/billyli/scope/particle_transformer/networks/ParT_w_hidden_states.py\",\n",
    "    \"--use-amp\",\n",
    "    \"--model-prefix\", \"/Users/billyli/scope/particle_transformer/models/ParT_full.pt\",\n",
    "    \"--batch-size\", \"128\",\n",
    "    \"--predict-output\", \"/Users/billyli/scope/particle_transformer/tmp/test_output.root\",\n",
    "    \"--gpus\", \"\",\n",
    "    \"--num-workers\", \"0\",\n",
    "    \"--disable-mps\",\n",
    "    \"--hidden-states\"\n",
    "])\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49069b2b",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2dfcf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders, data_config = test_load(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae154df5",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d433bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpus:\n",
    "    # distributed training\n",
    "    if args.backend is not None:\n",
    "        local_rank = args.local_rank\n",
    "        torch.cuda.set_device(local_rank)\n",
    "        gpus = [local_rank]\n",
    "        dev = torch.device(local_rank)\n",
    "        torch.distributed.init_process_group(backend=args.backend)\n",
    "        _logger.info(f'Using distributed PyTorch with {args.backend} backend')\n",
    "    else:\n",
    "        gpus = [int(i) for i in args.gpus.split(',')]\n",
    "        dev = torch.device(gpus[0])\n",
    "else:\n",
    "    gpus = None\n",
    "    dev = torch.device('cpu')\n",
    "    if not args.disable_mps:\n",
    "        try:\n",
    "            if torch.backends.mps.is_available():\n",
    "                dev = torch.device('mps')\n",
    "        except AttributeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8c6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billyli/miniforge_x86_new/envs/weaver/lib/python3.7/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Loss function not defined in /Users/billyli/scope/particle_transformer/networks/ParT_w_hidden_states.py. Will use `torch.nn.CrossEntropyLoss()` by default.\n"
     ]
    }
   ],
   "source": [
    "model, model_info, loss_func = model_setup(args, data_config, device=dev)\n",
    "model = model.to(dev)\n",
    "model_path = args.model_prefix if args.model_prefix.endswith(\n",
    "                '.pt') else args.model_prefix + '_best_epoch_state.pt'\n",
    "_logger.info('Loading model %s for eval' % model_path)\n",
    "model.load_state_dict(torch.load(model_path, map_location=dev))\n",
    "if gpus is not None and len(gpus) > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=gpus)\n",
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8e09e",
   "metadata": {},
   "source": [
    "## Calculte Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03ce7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, get_test_loader in test_loaders.items():\n",
    "    test_loader = get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100134bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "data_config = test_loader.dataset.config\n",
    "\n",
    "label_counter = Counter()\n",
    "total_loss = 0\n",
    "num_batches = 0\n",
    "total_correct = 0\n",
    "entry_count = 0\n",
    "count = 0\n",
    "scores = []\n",
    "labels = defaultdict(list)\n",
    "labels_counts = []\n",
    "observers = defaultdict(list)\n",
    "hiddens = []\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7c6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.register_tcav_layer(\"mod.norm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e48977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Restarting DataIter test_, seed=None ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billyli/miniforge_x86_new/envs/weaver/lib/python3.7/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "1it [00:05,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-1.0705e-03, -1.7459e-04, -1.0588e-04,  ..., -1.4244e-04,\n",
      "         -2.2214e-04, -1.1570e-04],\n",
      "        [-1.3032e-03, -1.4071e-04,  6.4780e-05,  ...,  4.7366e-06,\n",
      "         -2.3196e-04, -7.1918e-05],\n",
      "        [-1.2833e-03, -4.8746e-04, -5.7918e-04,  ..., -2.4301e-04,\n",
      "         -3.7723e-04, -4.8216e-04],\n",
      "        ...,\n",
      "        [-1.4722e-03, -3.0158e-04, -3.0450e-04,  ..., -2.9749e-04,\n",
      "         -3.0271e-04, -3.1144e-04],\n",
      "        [-9.1181e-04, -9.7223e-05, -2.2547e-04,  ..., -8.6482e-05,\n",
      "         -1.7573e-04, -1.0130e-04],\n",
      "        [-8.1403e-04, -5.2182e-04, -3.5538e-04,  ..., -1.4816e-04,\n",
      "         -5.4643e-04, -5.2116e-04]])\n",
      "acts tensor([[ 0.8622,  0.6470, -2.0281,  ..., -0.6050,  2.4926, -1.6463],\n",
      "        [-0.9107, -1.2412, -3.5839,  ..., -2.8996, -0.2032, -2.0256],\n",
      "        [ 1.6379, -2.6126, -3.8140,  ...,  0.5892, -1.1663, -2.5431],\n",
      "        ...,\n",
      "        [ 4.0475, -1.1442, -1.6574,  ..., -0.4289, -1.3053, -2.8669],\n",
      "        [-0.9764, -0.4170,  2.1545,  ..., -0.6325,  1.1542, -0.3354],\n",
      "        [ 4.0488, -0.9480, -0.0475,  ...,  1.0739, -1.0800, -0.9444]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:11,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-1.2117e-03, -2.5649e-04, -2.6270e-04,  ..., -2.4044e-04,\n",
      "         -2.5798e-04, -2.5096e-04],\n",
      "        [-8.4738e-04, -3.9467e-04, -8.7526e-04,  ..., -3.6555e-04,\n",
      "         -5.0501e-04, -5.0358e-04],\n",
      "        [-1.1464e-03, -2.6904e-04, -2.4613e-04,  ..., -1.7773e-04,\n",
      "         -3.0074e-04, -2.6031e-04],\n",
      "        ...,\n",
      "        [-1.1131e-03, -3.4293e-04, -5.1087e-04,  ..., -2.1375e-04,\n",
      "         -2.8746e-04, -3.4646e-04],\n",
      "        [-1.1316e-03, -2.7434e-04, -3.6717e-04,  ..., -2.3015e-04,\n",
      "         -2.9905e-04, -2.0400e-04],\n",
      "        [-1.0235e-03, -3.2016e-04, -2.5542e-04,  ...,  9.4877e-06,\n",
      "         -3.9651e-04, -3.5732e-04]])\n",
      "acts tensor([[ 3.2385, -0.1857, -0.7922,  ...,  1.3820, -0.3139,  0.3554],\n",
      "        [ 6.2643,  0.3387, -3.6791,  ...,  0.5822, -0.5821, -0.5718],\n",
      "        [ 2.4885,  0.3706,  0.9692,  ...,  2.7578, -0.4536,  0.5991],\n",
      "        ...,\n",
      "        [ 1.0460,  0.1797, -1.4636,  ...,  1.4437,  0.7238,  0.1451],\n",
      "        [ 3.7467,  0.9146, -0.4704,  ...,  1.5739,  0.5486,  1.9639],\n",
      "        [ 3.1054,  0.3925,  0.8474,  ...,  2.7093, -0.1428,  0.1314]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:17,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-1.1384e-03, -2.3432e-04, -2.5627e-04,  ..., -2.1030e-04,\n",
      "         -2.3883e-04, -2.3603e-04],\n",
      "        [-8.2101e-04, -3.2081e-04, -4.4179e-04,  ..., -1.4804e-04,\n",
      "         -3.8474e-04, -3.1290e-04],\n",
      "        [-8.9343e-04, -3.1853e-04, -3.7822e-04,  ..., -9.9574e-06,\n",
      "         -3.9494e-04, -2.6040e-04],\n",
      "        ...,\n",
      "        [-2.1702e-03, -7.9525e-04, -9.8955e-04,  ..., -1.1938e-03,\n",
      "         -7.7310e-04, -8.7940e-04],\n",
      "        [-1.6848e-03, -4.9071e-04, -3.3351e-04,  ..., -4.5307e-04,\n",
      "         -2.8467e-04, -6.5395e-04],\n",
      "        [-1.7464e-03, -8.8669e-04, -8.3429e-04,  ..., -7.4235e-04,\n",
      "         -4.8730e-04, -5.4423e-04]])\n",
      "acts tensor([[ 1.3439,  0.8229, -0.5327,  ...,  2.3071,  0.5546,  0.7175],\n",
      "        [ 4.9724,  0.6641, -0.4539,  ...,  2.2606,  0.0749,  0.7372],\n",
      "        [ 3.9028,  0.1443, -0.4222,  ...,  3.0728, -0.5792,  0.6961],\n",
      "        ...,\n",
      "        [-4.4938, -3.5217, -4.4721,  ..., -5.4713, -3.4124, -3.9333],\n",
      "        [-7.4546, -5.9526, -2.7414,  ..., -5.1836, -1.7395, -9.2873],\n",
      "        [-4.1027, -5.8700, -5.4760,  ..., -4.7845, -2.8652, -3.2947]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:26,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-1.5303e-03, -4.4282e-04, -4.5502e-04,  ..., -4.3107e-04,\n",
      "         -2.9678e-04, -3.0052e-04],\n",
      "        [-1.8287e-03, -8.0757e-04, -7.0824e-04,  ..., -7.2970e-04,\n",
      "         -3.7866e-04, -6.5044e-04],\n",
      "        [-1.7380e-03, -7.2167e-04, -9.7322e-04,  ..., -6.7990e-04,\n",
      "         -3.8810e-04, -4.0157e-04],\n",
      "        ...,\n",
      "        [-1.7846e-03, -4.5350e-05, -1.9220e-04,  ..., -1.2969e-04,\n",
      "         -2.9415e-04, -3.9461e-04],\n",
      "        [-1.2106e-03, -2.7111e-05, -1.7389e-04,  ..., -1.5323e-04,\n",
      "         -2.5238e-04, -2.4419e-04],\n",
      "        [-1.0274e-03, -8.0724e-06, -6.8440e-05,  ...,  9.3098e-05,\n",
      "         -2.1462e-04, -2.2813e-04]])\n",
      "acts tensor([[-8.8504, -5.5690, -5.8252,  ..., -5.3223, -2.5013, -2.5832],\n",
      "        [-6.1937, -6.6242, -5.7490,  ..., -5.9380, -2.8430, -5.2395],\n",
      "        [-3.7838, -4.4011, -6.4968,  ..., -4.0530, -1.6206, -1.7343],\n",
      "        ...,\n",
      "        [ 0.3944, -4.3864, -2.7241,  ..., -3.4319, -1.5729, -0.4333],\n",
      "        [-5.5672, -5.9331, -3.5983,  ..., -3.9272, -2.3534, -2.4806],\n",
      "        [-6.0769, -5.0297, -4.1122,  ..., -6.5673, -1.8937, -1.6856]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:30,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-1.8447e-03, -3.1782e-05, -1.8794e-04,  ..., -1.7229e-04,\n",
      "         -3.1673e-04, -3.2691e-04],\n",
      "        [-1.2343e-03, -1.4651e-06, -9.6475e-05,  ..., -5.4668e-05,\n",
      "         -2.1769e-04, -2.2948e-04],\n",
      "        [-8.8162e-04,  3.2153e-05, -8.0473e-05,  ...,  8.3961e-05,\n",
      "         -2.5924e-04, -2.3172e-04],\n",
      "        ...,\n",
      "        [-1.8734e-03,  2.0496e-04,  6.6017e-04,  ...,  3.1096e-04,\n",
      "         -4.0518e-04, -2.8746e-04],\n",
      "        [-5.2548e-04,  3.0447e-04,  8.8507e-04,  ...,  3.6259e-04,\n",
      "         -2.6790e-04,  3.5428e-04],\n",
      "        [-9.3183e-04,  4.7312e-05,  3.2358e-04,  ..., -3.8832e-07,\n",
      "         -1.0902e-04,  4.0282e-04]])\n",
      "acts tensor([[ 1.5984, -4.5700, -2.7167,  ..., -2.9026, -1.1910, -1.0677],\n",
      "        [-4.6488, -5.6464, -4.2205,  ..., -4.8482, -2.4049, -2.2250],\n",
      "        [-5.6705, -4.2015, -2.6064,  ..., -4.9353, -0.0775, -0.4648],\n",
      "        ...,\n",
      "        [ 1.7451, -0.7579, -2.1885,  ..., -1.0911,  1.1589,  0.7897],\n",
      "        [-1.4569, -0.4925, -2.2272,  ..., -0.6662,  1.2170, -0.6413],\n",
      "        [ 0.6217,  0.5727, -0.9900,  ...,  0.8425,  1.4562, -1.4384]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:35,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-6.7028e-04,  7.5813e-04, -6.9563e-04,  ..., -1.2923e-04,\n",
      "         -1.3258e-04,  2.4723e-04],\n",
      "        [ 9.9851e-04,  7.0538e-04, -2.3326e-04,  ..., -3.9395e-04,\n",
      "          2.1434e-04,  1.9139e-03],\n",
      "        [ 1.3239e-03,  1.1354e-03, -1.2123e-03,  ...,  1.7846e-04,\n",
      "          1.1477e-03,  1.2545e-03],\n",
      "        ...,\n",
      "        [-2.0104e-03, -6.1570e-04,  2.3081e-05,  ..., -6.7576e-04,\n",
      "         -5.3849e-04, -6.5050e-04],\n",
      "        [-1.5772e-03, -4.1360e-04, -7.8476e-04,  ..., -5.0743e-04,\n",
      "         -4.5198e-04, -5.2917e-04],\n",
      "        [-1.6611e-03, -4.9042e-04, -8.9237e-04,  ..., -4.1519e-04,\n",
      "         -4.5423e-04, -4.6239e-04]])\n",
      "acts tensor([[-0.4681, -0.7121,  1.6705,  ...,  0.7422,  0.7473,  0.1252],\n",
      "        [-2.9043, -0.2093,  1.3752,  ...,  1.6465,  0.6192, -2.2495],\n",
      "        [-3.4313, -1.3289,  1.8035,  ..., -0.0521, -1.3456, -1.4878],\n",
      "        ...,\n",
      "        [-4.9403, -2.1747,  2.3835,  ..., -2.6032, -1.6225, -2.4229],\n",
      "        [-3.0192, -0.5733, -3.8324,  ..., -1.3972, -0.9090, -1.5881],\n",
      "        [-2.2959, -0.6902, -3.5568,  ..., -0.1536, -0.4309, -0.4902]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:40,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-0.0018, -0.0005, -0.0007,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0012, -0.0003, -0.0004,  ..., -0.0001, -0.0003, -0.0004],\n",
      "        [-0.0019, -0.0005, -0.0008,  ..., -0.0005, -0.0006, -0.0006],\n",
      "        ...,\n",
      "        [-0.0017, -0.0008, -0.0006,  ..., -0.0006, -0.0009, -0.0006],\n",
      "        [-0.0020, -0.0007, -0.0007,  ..., -0.0005, -0.0008, -0.0007],\n",
      "        [-0.0010, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n",
      "acts tensor([[-5.1392, -1.5579, -3.5484,  ..., -1.2735, -1.7209, -1.4107],\n",
      "        [-1.3121,  0.2479, -0.7614,  ...,  2.2561,  0.3236, -1.0340],\n",
      "        [-4.9306, -1.6131, -4.3081,  ..., -1.6173, -2.4113, -2.2028],\n",
      "        ...,\n",
      "        [-0.7816, -2.0408, -1.1250,  ..., -1.3274, -2.3371, -1.1918],\n",
      "        [-2.9194, -2.0298, -2.2858,  ..., -1.0394, -2.6797, -2.4895],\n",
      "        [-0.5788, -1.9769,  0.8191,  ...,  0.6353, -0.7042, -2.1818]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:42,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads tensor([[-0.0018, -0.0008, -0.0005,  ..., -0.0003, -0.0010, -0.0008],\n",
      "        [-0.0019, -0.0008, -0.0005,  ..., -0.0003, -0.0010, -0.0009],\n",
      "        [-0.0011, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        ...,\n",
      "        [-0.0010, -0.0004, -0.0004,  ..., -0.0002, -0.0004, -0.0004],\n",
      "        [-0.0012, -0.0004, -0.0006,  ..., -0.0004, -0.0003, -0.0004],\n",
      "        [-0.0014, -0.0004, -0.0006,  ..., -0.0005, -0.0004, -0.0004]])\n",
      "acts tensor([[-1.0064, -2.0154, -1.0625,  ..., -0.1655, -2.9232, -2.0782],\n",
      "        [-1.3858, -1.9703, -0.7161,  ..., -0.0759, -2.8316, -2.3233],\n",
      "        [-1.4903, -0.2969, -2.4878,  ..., -0.6575, -0.5126, -0.2503],\n",
      "        ...,\n",
      "        [ 2.3178,  0.1889, -0.4218,  ...,  1.5670,  0.2606,  0.3065],\n",
      "        [ 0.6941, -0.5219, -4.8899,  ...,  0.0295,  1.2677, -1.2587],\n",
      "        [-1.2034, -0.1063, -1.8450,  ..., -1.4266,  0.1330, -0.2339]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gs = []\n",
    "with tqdm(test_loader) as tq:\n",
    "    for X, y, Z in tq:\n",
    "        # X, y: torch.Tensor; Z: ak.Array\n",
    "        inputs = [X[k].to(dev) for k in data_config.input_names]\n",
    "        label = y[data_config.label_names[0]].long().to(dev)\n",
    "        entry_count += label.shape[0]\n",
    "\n",
    "        try:\n",
    "            mask = y[data_config.label_names[0] + '_mask'].bool().to(dev)\n",
    "        except KeyError:\n",
    "            mask = None\n",
    "        model_output = model(*inputs)\n",
    "        g = model.tcav_grads_from_batch(*inputs, class_idx=8) \n",
    "        gs.append(g.cpu().numpy()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a73527ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = np.concatenate(gs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550f841",
   "metadata": {},
   "source": [
    "## Load cav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9994165",
   "metadata": {},
   "outputs": [],
   "source": [
    "cav = h5.File('/Users/billyli/scope/particle_transformer/notebooks/rav_sdmass.h5', 'r')['RAV_jet_sdmass'][:]\n",
    "cav = cav[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac94644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_cav = cav / np.linalg.norm(cav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfa3719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "cadir_deriv = gs @ normalized_cav  # shape (N,)\n",
    "tcav = float((cadir_deriv  > 0).mean())\n",
    "print(tcav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b92796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0705204e-03, -1.3031547e-03, -1.2833124e-03, -1.0863956e-03,\n",
       "       -1.2782087e-03, -1.2245905e-03, -1.1331652e-03, -8.7467348e-04,\n",
       "       -1.4419832e-03, -1.1401846e-03, -1.1082630e-03, -1.1594278e-03,\n",
       "       -1.3063160e-03, -1.0285192e-03, -1.3628390e-03, -8.8517158e-04,\n",
       "       -1.2003947e-03, -1.3494641e-03, -1.2737323e-03, -1.1052706e-03,\n",
       "       -1.0131560e-03, -9.6922024e-04, -1.3155468e-03, -1.1098369e-03,\n",
       "       -1.3614972e-03, -1.3931772e-03, -1.1406268e-03, -1.2890535e-03,\n",
       "       -1.6585081e-03, -1.2997587e-03, -1.1295517e-03, -9.7025395e-04,\n",
       "       -1.4697411e-03, -1.1494958e-03, -1.6342890e-03, -1.3695704e-03,\n",
       "       -1.5165720e-03, -1.2361638e-03, -1.2402132e-03, -1.1187964e-03,\n",
       "       -1.4018831e-03, -1.3508550e-03, -1.3522693e-03, -1.3080584e-03,\n",
       "       -1.4560594e-03, -1.2622641e-03, -1.4761935e-03, -1.1277983e-03,\n",
       "       -1.2292753e-03, -1.3014469e-03, -1.1713859e-03, -1.1040382e-03,\n",
       "       -1.3137029e-03, -1.4429954e-03, -8.0329261e-04, -2.2106231e-03,\n",
       "       -1.2505818e-03, -1.0055271e-03, -4.9599353e-04, -1.2120899e-03,\n",
       "       -7.6827942e-04, -1.0349151e-03, -1.4328897e-03, -1.3795159e-03,\n",
       "       -1.1195890e-03, -9.4320573e-04, -1.3348003e-03, -1.4687856e-03,\n",
       "       -1.3028496e-03, -1.2559041e-03, -9.3608355e-04, -1.1864522e-03,\n",
       "       -1.0932619e-03, -1.0290231e-03, -1.0169699e-03, -1.2812575e-03,\n",
       "       -1.1993577e-03, -1.3682776e-03, -1.1632047e-03, -1.1182918e-03,\n",
       "       -1.0970091e-03, -1.1206728e-03, -1.3433769e-03, -1.1549226e-03,\n",
       "       -8.6259970e-04, -1.5477448e-03, -1.2799420e-03, -1.0954706e-03,\n",
       "       -1.3774836e-03, -1.5710705e-03, -1.3342751e-03, -1.4982597e-03,\n",
       "       -1.0260036e-03, -1.2177456e-03, -1.2403105e-03, -1.2396660e-03,\n",
       "       -9.5917942e-04, -1.1805713e-03, -1.3235161e-03, -1.2158685e-03,\n",
       "       -1.2302280e-03, -8.6373702e-04, -1.7340101e-03, -1.0404887e-03,\n",
       "       -1.0618842e-03, -8.7746087e-04, -1.5167567e-03, -1.4405736e-03,\n",
       "       -9.3056588e-04, -1.2897276e-03, -6.3972245e-04, -5.8677647e-04,\n",
       "       -1.3209695e-03, -2.9420792e-04, -1.1962681e-03, -1.1935986e-03,\n",
       "       -1.0015713e-03, -1.5111505e-03, -8.6414820e-04, -1.0453663e-03,\n",
       "       -1.3611049e-03, -1.2200321e-03, -1.4692368e-03, -1.7472772e-03,\n",
       "       -1.0171133e-03, -1.4722180e-03, -9.1180700e-04, -8.1403484e-04,\n",
       "       -1.2117012e-03, -8.4738177e-04, -1.1463767e-03, -1.5081982e-03,\n",
       "       -1.1205424e-03, -1.3849651e-03, -9.7437575e-04, -3.1650919e-04,\n",
       "       -1.3485585e-03, -8.2510215e-04, -1.1784357e-03, -1.4926868e-03,\n",
       "       -5.5834372e-04, -9.6224656e-04, -9.4136066e-04, -1.2299329e-03,\n",
       "       -1.0621111e-03, -1.5201402e-03, -1.4770089e-03, -1.0329877e-03,\n",
       "       -1.2827404e-03, -1.4592187e-03, -1.4696796e-03, -1.1556940e-03,\n",
       "       -1.4875783e-03, -1.4499985e-03, -1.1047276e-03, -1.0889927e-03,\n",
       "       -6.6135562e-04, -1.2345824e-03, -1.5771419e-03, -1.5344630e-03,\n",
       "       -9.5973175e-04, -8.6408347e-04, -1.2826575e-03, -1.1912731e-03,\n",
       "       -1.0805139e-03, -9.3631697e-04, -9.1672235e-04, -1.2233471e-03,\n",
       "       -1.0544723e-03, -1.4934436e-03, -1.3731465e-03, -1.4121942e-03,\n",
       "       -1.4394413e-03, -7.5540051e-04, -6.5906614e-04, -7.7470241e-04,\n",
       "       -5.3241599e-04, -8.2434772e-04, -1.3629210e-03, -1.5630503e-03,\n",
       "       -1.0320654e-03, -1.0043783e-03, -7.7704812e-04, -1.3591546e-03,\n",
       "       -1.4679505e-03, -1.0573904e-03, -1.1385932e-03, -1.2159984e-03,\n",
       "       -6.5636868e-04, -1.5834207e-03, -9.6168101e-04, -7.6375512e-04,\n",
       "       -9.5397478e-04, -1.4819372e-03, -1.5080096e-03, -1.1286584e-03,\n",
       "       -1.3191584e-03, -8.9046615e-04, -1.5018785e-03, -1.1511883e-03,\n",
       "       -3.4566090e-04, -1.1802157e-03, -9.0014609e-04, -1.1772227e-03,\n",
       "       -1.2948818e-03, -7.9102151e-04, -1.0734654e-03, -1.1160134e-03,\n",
       "       -1.1301198e-03, -8.9900353e-04, -1.3296561e-03, -1.5389960e-03,\n",
       "       -1.1672630e-03, -1.0766924e-03, -1.1620150e-03, -1.2045169e-03,\n",
       "       -7.6903665e-04, -9.7732327e-04, -9.6865051e-04, -1.2214110e-03,\n",
       "       -8.1723940e-04, -8.5766515e-04, -1.1293994e-03, -1.0741384e-03,\n",
       "       -1.5310568e-03, -1.0999319e-03, -5.9001485e-04, -1.1471470e-03,\n",
       "       -1.2244346e-03, -1.0786947e-03, -8.9179364e-04, -1.0543996e-03,\n",
       "       -6.3625461e-04, -9.7471179e-04, -1.0875349e-03, -8.4432156e-04,\n",
       "       -1.0914756e-03, -1.0135153e-03, -9.2364254e-04, -1.1144349e-03,\n",
       "       -1.0316514e-03, -7.6064526e-04, -8.9436851e-04, -6.2927627e-04,\n",
       "       -6.0200383e-04, -7.2845601e-04, -1.1384487e-03, -1.1450266e-03,\n",
       "       -9.5066591e-04, -6.8453356e-04, -1.0555335e-03, -8.0980663e-04,\n",
       "       -1.0994214e-03, -1.1131475e-03, -1.1315617e-03, -1.0234849e-03,\n",
       "       -1.1383919e-03, -8.2100823e-04, -8.9343428e-04, -1.1936098e-03,\n",
       "       -1.0381172e-03, -1.1505379e-03, -1.1348487e-03, -9.0172794e-04,\n",
       "       -8.6819008e-04, -8.8593253e-04, -1.0954828e-03, -1.1141289e-03,\n",
       "       -1.0021848e-03, -1.0158214e-03, -1.4994150e-03, -1.0814462e-03,\n",
       "       -9.1287773e-04, -1.0881057e-03, -9.8074460e-04, -1.1563039e-03,\n",
       "       -1.1458165e-03, -1.1221761e-03, -8.8111509e-04, -8.2445011e-04,\n",
       "       -8.5934263e-04, -1.2507181e-03, -1.0139644e-03, -1.1755091e-03,\n",
       "       -1.5690667e-03, -1.0965572e-03, -1.1671181e-03, -1.6423147e-03,\n",
       "       -1.0643706e-03, -1.1951780e-03, -1.3498196e-03, -8.7655446e-04,\n",
       "       -1.0321167e-03, -8.5496530e-04, -1.3186581e-03, -1.1347891e-03,\n",
       "       -4.7876217e-04, -1.0754899e-03, -1.0336700e-03, -1.1151973e-03,\n",
       "       -1.8634445e-03, -1.4934036e-03, -1.6160165e-03, -1.7776147e-03,\n",
       "       -1.6386595e-03, -1.5302501e-03, -2.4692712e-03, -1.2594050e-03,\n",
       "       -2.0872059e-03, -1.3322110e-03, -1.5148721e-03, -1.6204596e-03,\n",
       "       -1.4870015e-03, -1.5737077e-03, -1.6670828e-03, -1.8025471e-03,\n",
       "       -1.9692103e-03, -1.6963435e-03, -1.4375353e-03, -1.0545047e-03,\n",
       "       -1.8933996e-03, -1.5113096e-03, -1.8462841e-03, -1.3549615e-03,\n",
       "       -1.7812991e-03, -1.5594190e-03, -1.2943377e-03, -8.6806482e-04,\n",
       "       -2.4004101e-03, -2.2723977e-03, -2.1116205e-03, -1.7741906e-03,\n",
       "       -2.3024750e-03, -1.2488433e-03, -2.1262311e-03, -1.9429695e-03,\n",
       "       -1.4710865e-03, -1.3261451e-03, -1.3344678e-03, -1.7823001e-03,\n",
       "       -1.6718564e-03, -1.6391648e-03, -1.9343686e-03, -1.6988894e-03,\n",
       "       -1.2622887e-03, -1.7886051e-03, -1.6595805e-03, -1.4346860e-03,\n",
       "       -1.4053185e-03, -1.6825360e-03, -1.1107472e-03, -1.5648447e-03,\n",
       "       -1.5370464e-03, -8.6337951e-04, -1.6387010e-03, -1.3669144e-03,\n",
       "       -1.2739933e-03, -1.0640324e-03, -7.7443960e-04, -1.6665328e-03,\n",
       "       -1.9968825e-03, -2.0721850e-03, -2.0316360e-03, -9.4599725e-04,\n",
       "       -1.6822412e-03, -1.1886971e-03, -1.8887951e-03, -1.8646923e-03,\n",
       "       -1.3580261e-03, -2.4049487e-03, -1.3127505e-03, -1.3201962e-03,\n",
       "       -1.8516529e-03, -1.3326181e-03, -9.9882158e-04, -1.9475571e-03,\n",
       "       -2.0499404e-03, -1.9354937e-03, -1.2421331e-03, -1.6925049e-03,\n",
       "       -1.7572098e-03, -2.1701860e-03, -1.6847977e-03, -1.7463544e-03,\n",
       "       -1.5303411e-03, -1.8286812e-03, -1.7380230e-03, -1.9566272e-03,\n",
       "       -1.4967774e-03, -1.5114327e-03, -1.8742417e-03, -1.3235697e-03,\n",
       "       -1.6939880e-03, -1.5147357e-03, -1.3842070e-03, -1.4536361e-03,\n",
       "       -1.2261188e-03, -1.8476036e-03, -1.3513360e-03, -1.4550986e-03,\n",
       "       -1.2107376e-03, -9.3125761e-04, -1.1374590e-03, -1.1564248e-03,\n",
       "       -1.2528079e-03, -1.3502800e-03, -1.0892568e-03, -1.3407165e-03,\n",
       "       -7.3629653e-04, -1.4313876e-03, -1.2997591e-03, -1.4042275e-03,\n",
       "       -1.2306848e-03, -1.0124524e-03, -1.0916471e-03, -1.2840382e-03,\n",
       "       -1.2636695e-03, -1.0361006e-03, -1.1438071e-03, -1.1181718e-03,\n",
       "       -9.1568363e-04, -1.1145150e-03, -1.0935365e-03, -1.0301810e-03,\n",
       "       -1.7115071e-03, -9.6805801e-04, -1.0280025e-03, -9.6980092e-04,\n",
       "       -9.4127492e-04, -1.6026658e-03, -1.0221852e-03, -1.3954330e-03,\n",
       "       -1.1061307e-03, -1.2097261e-03, -8.7912043e-04, -1.4518264e-03,\n",
       "       -1.3451064e-03, -1.3576241e-03, -1.2608368e-03, -1.0249417e-03,\n",
       "       -1.2238142e-03, -1.2557919e-03, -1.0650702e-03, -1.4336077e-03,\n",
       "       -1.1180469e-03, -1.1033234e-03, -1.2485759e-03, -1.1945288e-03,\n",
       "       -8.1991800e-04, -1.5058430e-03, -1.1776747e-03, -1.1405236e-03,\n",
       "       -1.2524619e-03, -1.6479526e-03, -1.2276976e-03, -9.2578569e-04,\n",
       "       -1.0571425e-03, -1.1128732e-03, -1.1099839e-03, -1.1216623e-03,\n",
       "       -1.2682229e-03, -8.4022910e-04, -1.0302011e-03, -1.2829837e-03,\n",
       "       -1.2186639e-03, -9.6710154e-04, -1.4539445e-03, -1.1918868e-03,\n",
       "       -1.0696744e-03, -1.2065917e-03, -1.1902766e-03, -1.4208339e-03,\n",
       "       -1.1071110e-03, -1.2156914e-03, -9.1691071e-04, -1.3000483e-03,\n",
       "       -1.3521162e-03, -1.3624048e-03, -1.3910438e-04, -1.0165097e-03,\n",
       "       -1.2384226e-03, -1.1333976e-03, -6.0876575e-04, -1.1037089e-03,\n",
       "       -1.1586163e-03, -1.1541237e-03, -1.1992804e-03, -9.1662729e-04,\n",
       "       -1.2289353e-03, -1.5000354e-03, -1.4721848e-03, -1.1780221e-03,\n",
       "       -1.2553397e-03, -1.2203071e-03, -1.1761463e-03, -1.1037822e-03,\n",
       "       -1.1425763e-03, -1.2969320e-03, -1.2663226e-03, -1.2735059e-03,\n",
       "       -1.6566388e-03, -1.2948834e-03, -2.1860057e-03, -1.0419871e-03,\n",
       "       -5.6676182e-04, -1.6514304e-03, -1.1482779e-03, -1.1495110e-03,\n",
       "       -1.4323343e-03, -1.7846163e-03, -1.2105945e-03, -1.0273565e-03,\n",
       "       -1.8447150e-03, -1.2342706e-03, -8.8161684e-04, -1.1871749e-03,\n",
       "       -1.5552053e-03, -9.7110623e-04, -1.4784531e-03, -1.3583740e-03,\n",
       "       -8.6891220e-04, -1.3910513e-03, -1.1050284e-03, -1.1216786e-03,\n",
       "       -1.6148663e-03, -1.2901557e-03, -1.3794104e-03, -1.1134697e-03,\n",
       "       -4.6511402e-04, -2.0641699e-03, -9.5357257e-04, -1.3747031e-03,\n",
       "       -1.0768832e-03, -8.8164321e-04, -1.5432863e-03, -7.6496380e-04,\n",
       "       -1.6626837e-03, -1.5454623e-03, -1.1112716e-03, -7.8723143e-04,\n",
       "       -1.0117082e-03, -1.1646610e-03, -9.9111325e-04, -1.0763023e-03,\n",
       "       -1.7448075e-03, -1.7332528e-03, -1.5612171e-03, -1.4993647e-03,\n",
       "       -7.8041299e-04, -1.4651584e-03, -1.0171456e-03, -1.3082526e-03,\n",
       "       -1.6215707e-03, -1.9024867e-03, -1.1230647e-03, -1.2790989e-03,\n",
       "       -5.5022398e-04, -1.5290023e-03, -1.1671124e-03, -7.5515470e-04,\n",
       "       -5.5298652e-04, -1.9160229e-03, -1.3589433e-03, -1.3760309e-03,\n",
       "       -1.3894448e-03, -1.2388912e-03, -1.3169983e-03, -1.0811202e-03,\n",
       "       -1.6275682e-03, -1.1692522e-03, -1.4192940e-03, -1.4638325e-03,\n",
       "       -3.7919485e-04, -1.3830479e-03, -1.2715394e-03, -1.5704280e-03,\n",
       "       -1.5948015e-03, -1.2581056e-03, -1.2993453e-03, -2.3645573e-04,\n",
       "       -1.3028268e-03, -1.3213910e-03, -1.0006153e-03, -1.0423859e-03,\n",
       "       -1.4584712e-03, -1.1777228e-03, -1.5419127e-03, -1.6258793e-03,\n",
       "       -1.1843365e-03, -1.1971251e-03, -6.2373688e-04, -1.2371303e-03,\n",
       "       -1.4555061e-03, -8.8577141e-04, -1.2870965e-03, -1.1559265e-03,\n",
       "       -7.4970000e-04, -5.4372597e-04, -1.4168578e-03, -8.5165875e-04,\n",
       "       -1.1565319e-03, -1.0266145e-03,  1.3524038e-04, -1.3403521e-03,\n",
       "       -2.1630491e-03,  4.3662440e-04, -9.3184219e-04, -1.3081353e-03,\n",
       "       -5.3806632e-04, -1.2048971e-04, -2.2669695e-04, -7.8123622e-04,\n",
       "       -7.4573199e-04, -4.6835770e-04, -1.3238103e-03, -4.2569102e-04,\n",
       "       -9.3613315e-04, -4.8502086e-04,  3.4469232e-04,  3.9700099e-04,\n",
       "       -6.6238933e-04, -7.3245738e-04,  6.4197142e-05, -1.0506184e-03,\n",
       "        9.7965263e-04, -4.8102837e-04, -2.7084444e-04, -6.5351545e-05,\n",
       "       -1.1600766e-03, -8.4130932e-04, -9.7770884e-04, -3.6267593e-04,\n",
       "        2.7975088e-04, -1.2899153e-03, -4.5288954e-04, -4.9452705e-04,\n",
       "       -4.7757302e-04, -1.8734466e-03, -5.2547693e-04, -9.3183306e-04,\n",
       "       -6.7028013e-04,  9.9850842e-04,  1.3239364e-03,  7.0347078e-04,\n",
       "       -1.6763262e-04,  3.4496741e-05, -3.2238202e-04,  1.4540914e-05,\n",
       "       -1.0215419e-03, -7.0723373e-04, -1.0092849e-03, -9.0290565e-04,\n",
       "        6.2333414e-04, -8.4813480e-05,  2.2486920e-04, -3.1761065e-04,\n",
       "       -1.4709663e-03,  5.8550679e-05, -1.6873989e-03, -2.1015683e-03,\n",
       "       -1.2983622e-03, -1.9093290e-03, -4.7646018e-04, -3.5762825e-04,\n",
       "       -5.5779400e-04, -6.7503948e-04, -9.5784885e-04, -1.3910912e-03,\n",
       "       -9.2859939e-04, -6.7800190e-04, -7.5828203e-04, -9.5738558e-04,\n",
       "       -2.8299980e-04, -8.5499510e-04,  7.8036741e-05, -1.4209987e-03,\n",
       "       -2.0109687e-04, -8.4438303e-04, -4.4430626e-04, -1.2439796e-03,\n",
       "       -1.1507201e-03,  8.1303297e-05, -4.1840877e-04, -1.2456123e-03,\n",
       "       -1.0663469e-03, -2.7696250e-04, -2.2504915e-05, -1.1129498e-03,\n",
       "       -1.1580861e-03, -1.2929031e-03, -1.9411385e-03, -1.8045408e-04,\n",
       "       -4.9290044e-04, -6.3172972e-04, -1.3803337e-03, -9.3608437e-04,\n",
       "       -9.9052733e-04, -1.7925825e-03, -5.0017936e-04, -9.7192475e-05,\n",
       "       -1.2722142e-03, -1.6175425e-03, -1.7779438e-03, -1.9122076e-03,\n",
       "       -1.2839746e-03, -2.0930856e-03, -1.6851970e-03, -1.4720745e-03,\n",
       "       -1.4169905e-03, -1.2184065e-03, -1.9997982e-03, -1.2006115e-03,\n",
       "       -1.6659372e-03, -1.2402511e-03, -2.2035856e-03, -1.2000212e-03,\n",
       "       -1.9565723e-03, -1.8225160e-03, -2.1665690e-03, -1.6519621e-03,\n",
       "       -9.5318432e-04, -2.2847727e-03, -1.7761898e-03, -1.2254659e-03,\n",
       "       -1.2583132e-03, -1.7168482e-03, -1.6682404e-03, -1.6498135e-03,\n",
       "       -2.0257127e-03, -1.7131284e-03, -1.2733476e-03, -2.2886933e-03,\n",
       "       -1.3541412e-03, -1.6746310e-03, -2.1226760e-03, -2.2237236e-03,\n",
       "       -1.8503948e-03, -2.1938209e-03, -9.0448931e-04, -1.4157051e-03,\n",
       "       -1.5064777e-03, -1.4142909e-03, -1.8573487e-03, -1.7330260e-03,\n",
       "       -1.3851114e-03, -2.2355199e-03, -1.3167397e-03, -1.8860507e-03,\n",
       "       -2.3805797e-03, -1.9284864e-03, -1.7597785e-03, -1.7460790e-03,\n",
       "       -1.8228248e-03, -1.8318804e-03, -2.0903894e-03, -8.8928250e-04,\n",
       "       -2.0501777e-03, -2.0493474e-03, -1.8489461e-03, -1.7018806e-03,\n",
       "       -2.2068387e-03, -1.1367683e-03, -1.2445976e-03, -1.7989026e-03,\n",
       "       -2.1653005e-03, -2.0103501e-03, -1.5771929e-03, -1.6610825e-03,\n",
       "       -1.8133034e-03, -1.1908585e-03, -1.8858879e-03, -1.2226072e-03,\n",
       "       -1.5447896e-03, -1.7259724e-03, -2.0830934e-03, -2.1231272e-03,\n",
       "       -2.4124100e-03, -1.6897011e-03, -1.3501651e-03, -2.3721214e-03,\n",
       "       -1.6383075e-03, -2.4642614e-03, -1.5732630e-03, -2.1681099e-03,\n",
       "       -1.9918245e-03, -1.4074179e-03, -1.8268388e-03, -2.1828217e-03,\n",
       "       -2.0615114e-03, -1.0466288e-03, -1.6117956e-03, -1.5592728e-03,\n",
       "       -2.0841514e-03, -1.4152864e-03, -6.0227670e-04, -2.2157866e-03,\n",
       "       -1.8491216e-03, -1.2596856e-03, -2.1998466e-03, -2.1781579e-03,\n",
       "       -1.1865303e-03, -1.8163341e-03, -1.3436456e-03, -1.4845341e-03,\n",
       "       -9.4317825e-04, -1.7362963e-03, -1.0086684e-03, -1.3468856e-03,\n",
       "       -1.4533959e-03, -1.5759679e-03, -1.7350157e-03, -7.7064638e-04,\n",
       "       -1.2171420e-03, -1.5886034e-03, -1.3761611e-03, -1.2816845e-03,\n",
       "       -1.7307368e-03, -1.6462260e-03, -1.3720745e-03, -1.2529622e-03,\n",
       "       -2.1799887e-03, -1.2039579e-03, -1.0946442e-03, -1.5181099e-03,\n",
       "       -1.9197958e-03, -1.3661988e-03, -1.5898885e-03, -1.3760875e-03,\n",
       "       -1.2557061e-03, -1.5556081e-03, -1.5278028e-03, -1.1555445e-03,\n",
       "       -1.8414333e-03, -9.3002309e-04, -1.0811136e-03, -1.3231621e-03,\n",
       "       -1.6285244e-03, -1.6613074e-03, -1.3637932e-03, -8.5460668e-04,\n",
       "       -1.2042881e-03, -1.7005932e-03, -1.1735517e-03, -1.8273966e-03,\n",
       "       -9.7715599e-04, -1.5199834e-03, -1.5611541e-03, -1.4185939e-03,\n",
       "       -1.1699625e-03, -1.8558950e-03, -1.6963236e-03, -1.2577409e-03,\n",
       "       -1.3652853e-03, -9.1516064e-04, -1.3661247e-03, -1.3904448e-03,\n",
       "       -1.5084756e-03, -1.6246117e-03, -1.2492067e-03, -9.1732189e-04,\n",
       "       -1.5361699e-03, -1.8101269e-03, -1.6682190e-03, -1.6715118e-03,\n",
       "       -1.7049115e-03, -1.3742074e-03, -1.5899681e-03, -1.1636564e-03,\n",
       "       -1.7187501e-03, -1.2609356e-03, -2.0141958e-03, -1.6285855e-03,\n",
       "       -1.4993380e-03, -1.2736260e-03, -1.6210887e-03, -7.5242174e-04,\n",
       "       -9.2195097e-04, -1.4077036e-03, -9.3203626e-04, -1.1590190e-03,\n",
       "       -1.4474418e-03, -1.0536220e-03, -1.1755453e-03, -1.7351938e-03,\n",
       "       -1.5967059e-03, -1.7436598e-03, -1.0399470e-03, -1.0968846e-03,\n",
       "       -1.2563696e-03, -1.6150355e-03, -1.6179786e-03, -1.1464268e-03,\n",
       "       -1.2697912e-03, -1.6687394e-03, -1.9615535e-03, -1.0248539e-03,\n",
       "       -1.7855319e-03, -1.9225652e-03, -1.1322792e-03, -1.4374302e-03,\n",
       "       -9.2936557e-04, -1.8982124e-03, -1.7338621e-03, -1.1892333e-03,\n",
       "       -1.1962140e-03, -1.3536520e-03, -1.2705068e-03, -1.9948154e-03,\n",
       "       -1.2818720e-03, -1.5906511e-03, -8.0718304e-04, -7.1163638e-04,\n",
       "       -2.1406347e-03, -1.4721993e-03, -1.0474906e-03, -1.4903244e-03,\n",
       "       -1.7757491e-03, -1.1840230e-03, -9.8705792e-04, -1.5840802e-03,\n",
       "       -9.7665517e-04, -2.1042060e-03, -9.8735222e-04, -1.1476059e-03,\n",
       "       -1.2310407e-03, -1.0853038e-03, -1.1388663e-03, -1.2391605e-03,\n",
       "       -4.5833460e-04, -2.0144472e-03, -1.1618803e-03, -1.6112475e-03,\n",
       "       -1.1840428e-03, -2.4424095e-03, -2.1424745e-03, -1.3358872e-03,\n",
       "       -1.7079122e-03, -2.0840617e-03, -9.8352192e-04, -7.4708898e-04,\n",
       "       -8.8071637e-04, -1.2791755e-03, -1.3984214e-03, -2.1518387e-03,\n",
       "       -1.4484705e-03,  4.3149717e-05, -8.8925823e-04, -3.9236707e-04,\n",
       "       -2.0543265e-04, -2.1049082e-03, -2.4166123e-03, -1.7386468e-03,\n",
       "       -1.4944514e-03, -1.7310350e-03, -1.1131389e-03, -1.3212984e-03,\n",
       "       -1.4661974e-03, -6.3197990e-04, -1.4820066e-03, -1.0236412e-03,\n",
       "       -1.3152489e-03, -1.1385153e-03, -1.2903174e-03, -1.7341336e-03,\n",
       "       -1.8365674e-03, -8.5743627e-04, -6.9765822e-04, -1.3507737e-03,\n",
       "       -1.7093845e-03, -1.0926715e-03, -1.1779992e-03, -1.8229132e-03,\n",
       "       -1.8799780e-03, -8.7465812e-04, -7.4830337e-04, -1.0056752e-03,\n",
       "       -1.2240910e-03, -2.0492019e-03, -2.0750493e-03, -1.0426608e-03,\n",
       "       -6.6599838e-04, -1.1533347e-03, -1.1297476e-03, -1.8437232e-03,\n",
       "       -2.1920882e-03, -1.7037787e-03, -4.7832390e-04, -1.6048714e-03,\n",
       "       -1.5441864e-03, -1.5638038e-03, -1.5148796e-03, -8.5366849e-04,\n",
       "       -1.3686505e-03, -1.8366782e-03, -1.2500801e-03, -2.2746616e-03,\n",
       "       -7.3762797e-04, -1.0283224e-03, -1.1791266e-03, -1.3698358e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf0d021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00061564],\n",
       "       [0.00080163],\n",
       "       [0.00076082],\n",
       "       [0.00076636],\n",
       "       [0.00074594],\n",
       "       [0.00070806],\n",
       "       [0.00061166],\n",
       "       [0.00068055],\n",
       "       [0.00075212],\n",
       "       [0.00068854],\n",
       "       [0.00058322],\n",
       "       [0.00058469],\n",
       "       [0.0007332 ],\n",
       "       [0.00063378],\n",
       "       [0.00077886],\n",
       "       [0.00060006],\n",
       "       [0.00073154],\n",
       "       [0.00076531],\n",
       "       [0.00074341],\n",
       "       [0.00066724],\n",
       "       [0.00075736],\n",
       "       [0.00069177],\n",
       "       [0.00078488],\n",
       "       [0.00077366],\n",
       "       [0.00068688],\n",
       "       [0.00073133],\n",
       "       [0.00071468],\n",
       "       [0.0006862 ],\n",
       "       [0.00071113],\n",
       "       [0.00073873],\n",
       "       [0.00067779],\n",
       "       [0.0006057 ],\n",
       "       [0.00080783],\n",
       "       [0.00073351],\n",
       "       [0.00078332],\n",
       "       [0.00067745],\n",
       "       [0.00064432],\n",
       "       [0.00069073],\n",
       "       [0.00075214],\n",
       "       [0.00072202],\n",
       "       [0.00073741],\n",
       "       [0.00075096],\n",
       "       [0.00083136],\n",
       "       [0.00074581],\n",
       "       [0.00076608],\n",
       "       [0.00071389],\n",
       "       [0.00077273],\n",
       "       [0.0006365 ],\n",
       "       [0.00072834],\n",
       "       [0.00075061],\n",
       "       [0.0006914 ],\n",
       "       [0.00068759],\n",
       "       [0.0007339 ],\n",
       "       [0.00075036],\n",
       "       [0.00071375],\n",
       "       [0.00091738],\n",
       "       [0.0007574 ],\n",
       "       [0.00078155],\n",
       "       [0.00076451],\n",
       "       [0.00065571],\n",
       "       [0.00075488],\n",
       "       [0.00056227],\n",
       "       [0.00082964],\n",
       "       [0.00076915],\n",
       "       [0.00057557],\n",
       "       [0.00065623],\n",
       "       [0.00068252],\n",
       "       [0.00070763],\n",
       "       [0.00075123],\n",
       "       [0.0007187 ],\n",
       "       [0.00063535],\n",
       "       [0.00072449],\n",
       "       [0.00073692],\n",
       "       [0.00059094],\n",
       "       [0.00064886],\n",
       "       [0.0007522 ],\n",
       "       [0.00070364],\n",
       "       [0.00059984],\n",
       "       [0.00072024],\n",
       "       [0.00072166],\n",
       "       [0.00067447],\n",
       "       [0.00076737],\n",
       "       [0.00073986],\n",
       "       [0.00072558],\n",
       "       [0.00072807],\n",
       "       [0.00079707],\n",
       "       [0.00069551],\n",
       "       [0.00069572],\n",
       "       [0.00077505],\n",
       "       [0.00071087],\n",
       "       [0.00070579],\n",
       "       [0.0008454 ],\n",
       "       [0.00073974],\n",
       "       [0.00063114],\n",
       "       [0.00071368],\n",
       "       [0.00069632],\n",
       "       [0.0007752 ],\n",
       "       [0.00062763],\n",
       "       [0.00073925],\n",
       "       [0.00063932],\n",
       "       [0.00073478],\n",
       "       [0.00076743],\n",
       "       [0.00102806],\n",
       "       [0.00067959],\n",
       "       [0.00069369],\n",
       "       [0.00073812],\n",
       "       [0.00085745],\n",
       "       [0.0008091 ],\n",
       "       [0.00079867],\n",
       "       [0.00071194],\n",
       "       [0.00091688],\n",
       "       [0.00092061],\n",
       "       [0.00081906],\n",
       "       [0.00087232],\n",
       "       [0.00076235],\n",
       "       [0.00067289],\n",
       "       [0.00072716],\n",
       "       [0.00083087],\n",
       "       [0.00089997],\n",
       "       [0.00063958],\n",
       "       [0.00072784],\n",
       "       [0.00067332],\n",
       "       [0.00085587],\n",
       "       [0.00060257],\n",
       "       [0.00077477],\n",
       "       [0.0008387 ],\n",
       "       [0.00056954],\n",
       "       [0.00082981],\n",
       "       [0.00069182],\n",
       "       [0.00084604],\n",
       "       [0.00066449],\n",
       "       [0.00085004],\n",
       "       [0.00069626],\n",
       "       [0.00077741],\n",
       "       [0.00066972],\n",
       "       [0.00090483],\n",
       "       [0.0008716 ],\n",
       "       [0.0006834 ],\n",
       "       [0.0007614 ],\n",
       "       [0.0007116 ],\n",
       "       [0.00074718],\n",
       "       [0.00061796],\n",
       "       [0.00082513],\n",
       "       [0.00090738],\n",
       "       [0.00071333],\n",
       "       [0.0008823 ],\n",
       "       [0.00086468],\n",
       "       [0.00078034],\n",
       "       [0.00072503],\n",
       "       [0.00078651],\n",
       "       [0.00084347],\n",
       "       [0.00069982],\n",
       "       [0.00094408],\n",
       "       [0.00070232],\n",
       "       [0.00065866],\n",
       "       [0.00073042],\n",
       "       [0.00092176],\n",
       "       [0.00079778],\n",
       "       [0.00072439],\n",
       "       [0.00070669],\n",
       "       [0.0006313 ],\n",
       "       [0.00083226],\n",
       "       [0.00071977],\n",
       "       [0.00087166],\n",
       "       [0.00065914],\n",
       "       [0.00079702],\n",
       "       [0.00086405],\n",
       "       [0.00069383],\n",
       "       [0.00071712],\n",
       "       [0.00080507],\n",
       "       [0.00085821],\n",
       "       [0.00084463],\n",
       "       [0.00078291],\n",
       "       [0.00063668],\n",
       "       [0.00085714],\n",
       "       [0.00069957],\n",
       "       [0.00081654],\n",
       "       [0.00065214],\n",
       "       [0.00077774],\n",
       "       [0.00063461],\n",
       "       [0.00086488],\n",
       "       [0.0007153 ],\n",
       "       [0.00073564],\n",
       "       [0.00081256],\n",
       "       [0.00080788],\n",
       "       [0.0008354 ],\n",
       "       [0.00079519],\n",
       "       [0.0007932 ],\n",
       "       [0.00087994],\n",
       "       [0.00088553],\n",
       "       [0.00087137],\n",
       "       [0.00087879],\n",
       "       [0.0007433 ],\n",
       "       [0.00084056],\n",
       "       [0.00076378],\n",
       "       [0.00065928],\n",
       "       [0.00078497],\n",
       "       [0.00076932],\n",
       "       [0.000853  ],\n",
       "       [0.0007916 ],\n",
       "       [0.00081894],\n",
       "       [0.00070079],\n",
       "       [0.00074035],\n",
       "       [0.0006852 ],\n",
       "       [0.00075883],\n",
       "       [0.00066781],\n",
       "       [0.00054701],\n",
       "       [0.00073113],\n",
       "       [0.00056853],\n",
       "       [0.00061645],\n",
       "       [0.00073636],\n",
       "       [0.00067301],\n",
       "       [0.00075426],\n",
       "       [0.00069306],\n",
       "       [0.0005792 ],\n",
       "       [0.00082251],\n",
       "       [0.00062224],\n",
       "       [0.00068546],\n",
       "       [0.00068534],\n",
       "       [0.00068276],\n",
       "       [0.00069498],\n",
       "       [0.00070234],\n",
       "       [0.00062869],\n",
       "       [0.00073097],\n",
       "       [0.00064236],\n",
       "       [0.00061437],\n",
       "       [0.00078659],\n",
       "       [0.00064001],\n",
       "       [0.00071938],\n",
       "       [0.00081171],\n",
       "       [0.00062581],\n",
       "       [0.00074207],\n",
       "       [0.00078591],\n",
       "       [0.00064496],\n",
       "       [0.00065442],\n",
       "       [0.00065364],\n",
       "       [0.00059873],\n",
       "       [0.00060962],\n",
       "       [0.00072424],\n",
       "       [0.00070467],\n",
       "       [0.00070621],\n",
       "       [0.00070933],\n",
       "       [0.00068453],\n",
       "       [0.00069586],\n",
       "       [0.00069378],\n",
       "       [0.00074213],\n",
       "       [0.00062463],\n",
       "       [0.00064636],\n",
       "       [0.00057579],\n",
       "       [0.00060525],\n",
       "       [0.00072502],\n",
       "       [0.00073126],\n",
       "       [0.00064178],\n",
       "       [0.00061795],\n",
       "       [0.00073585],\n",
       "       [0.00076492],\n",
       "       [0.00063778],\n",
       "       [0.00070045],\n",
       "       [0.00067256],\n",
       "       [0.00066975],\n",
       "       [0.00060681],\n",
       "       [0.00067145],\n",
       "       [0.00067061],\n",
       "       [0.00071034],\n",
       "       [0.00062178],\n",
       "       [0.0007999 ],\n",
       "       [0.00070303],\n",
       "       [0.00073701],\n",
       "       [0.00073044],\n",
       "       [0.00055784],\n",
       "       [0.00081728],\n",
       "       [0.00071167],\n",
       "       [0.00067385],\n",
       "       [0.00070872],\n",
       "       [0.00059   ],\n",
       "       [0.00078082],\n",
       "       [0.0006524 ],\n",
       "       [0.00069125],\n",
       "       [0.00067202],\n",
       "       [0.00076838],\n",
       "       [0.00076037],\n",
       "       [0.00070364],\n",
       "       [0.00058517],\n",
       "       [0.0007724 ],\n",
       "       [0.00080335],\n",
       "       [0.00065293],\n",
       "       [0.00071268],\n",
       "       [0.0007624 ],\n",
       "       [0.00077338],\n",
       "       [0.00069544],\n",
       "       [0.00075401],\n",
       "       [0.00073485],\n",
       "       [0.00069631],\n",
       "       [0.00069593],\n",
       "       [0.00073811],\n",
       "       [0.00066038],\n",
       "       [0.00071818],\n",
       "       [0.00072221],\n",
       "       [0.00063008],\n",
       "       [0.00072528],\n",
       "       [0.00081683],\n",
       "       [0.00064479],\n",
       "       [0.00079966],\n",
       "       [0.00073698],\n",
       "       [0.00080783],\n",
       "       [0.00081464],\n",
       "       [0.00081117],\n",
       "       [0.0007219 ],\n",
       "       [0.00071449],\n",
       "       [0.00067333],\n",
       "       [0.00076407],\n",
       "       [0.00084803],\n",
       "       [0.00067666],\n",
       "       [0.0008644 ],\n",
       "       [0.00074084],\n",
       "       [0.00071491],\n",
       "       [0.00084181],\n",
       "       [0.0007447 ],\n",
       "       [0.00079754],\n",
       "       [0.00086371],\n",
       "       [0.00075499],\n",
       "       [0.00073287],\n",
       "       [0.00075545],\n",
       "       [0.00073053],\n",
       "       [0.00095574],\n",
       "       [0.00090268],\n",
       "       [0.00076083],\n",
       "       [0.00067412],\n",
       "       [0.00087236],\n",
       "       [0.00087009],\n",
       "       [0.00087056],\n",
       "       [0.00084017],\n",
       "       [0.00102163],\n",
       "       [0.00073833],\n",
       "       [0.0009057 ],\n",
       "       [0.00105096],\n",
       "       [0.00083776],\n",
       "       [0.00056882],\n",
       "       [0.0005651 ],\n",
       "       [0.00093813],\n",
       "       [0.00076626],\n",
       "       [0.00072708],\n",
       "       [0.0008835 ],\n",
       "       [0.00068205],\n",
       "       [0.00064541],\n",
       "       [0.00073256],\n",
       "       [0.0007823 ],\n",
       "       [0.00075581],\n",
       "       [0.00067512],\n",
       "       [0.00098241],\n",
       "       [0.00063026],\n",
       "       [0.00073417],\n",
       "       [0.00074188],\n",
       "       [0.00068519],\n",
       "       [0.00092566],\n",
       "       [0.00074845],\n",
       "       [0.00094977],\n",
       "       [0.00064858],\n",
       "       [0.0009453 ],\n",
       "       [0.0006638 ],\n",
       "       [0.0006667 ],\n",
       "       [0.0006905 ],\n",
       "       [0.00060118],\n",
       "       [0.00059711],\n",
       "       [0.00096737],\n",
       "       [0.00064165],\n",
       "       [0.00090992],\n",
       "       [0.00062296],\n",
       "       [0.00064608],\n",
       "       [0.00071676],\n",
       "       [0.00069542],\n",
       "       [0.00061658],\n",
       "       [0.0006953 ],\n",
       "       [0.00061315],\n",
       "       [0.00064979],\n",
       "       [0.00070926],\n",
       "       [0.00081369],\n",
       "       [0.00070676],\n",
       "       [0.00070164],\n",
       "       [0.00088289],\n",
       "       [0.00062933],\n",
       "       [0.00078754],\n",
       "       [0.00074671],\n",
       "       [0.00072271],\n",
       "       [0.00063999],\n",
       "       [0.00067223],\n",
       "       [0.00071348],\n",
       "       [0.00078483],\n",
       "       [0.0008703 ],\n",
       "       [0.00073956],\n",
       "       [0.00081666],\n",
       "       [0.00083589],\n",
       "       [0.00079656],\n",
       "       [0.00105393],\n",
       "       [0.00091575],\n",
       "       [0.00074529],\n",
       "       [0.00060349],\n",
       "       [0.00087629],\n",
       "       [0.00072031],\n",
       "       [0.0006257 ],\n",
       "       [0.00068286],\n",
       "       [0.00059359],\n",
       "       [0.00073059],\n",
       "       [0.00071405],\n",
       "       [0.00075504],\n",
       "       [0.00078609],\n",
       "       [0.00065517],\n",
       "       [0.00078083],\n",
       "       [0.00061263],\n",
       "       [0.00088145],\n",
       "       [0.00075421],\n",
       "       [0.00085399],\n",
       "       [0.00070646],\n",
       "       [0.00065839],\n",
       "       [0.00060268],\n",
       "       [0.00072189],\n",
       "       [0.00071304],\n",
       "       [0.00070437],\n",
       "       [0.00069395],\n",
       "       [0.00061871],\n",
       "       [0.00084097],\n",
       "       [0.00071131],\n",
       "       [0.00068001],\n",
       "       [0.00071191],\n",
       "       [0.0007814 ],\n",
       "       [0.00065275],\n",
       "       [0.00065932],\n",
       "       [0.00076399],\n",
       "       [0.00064067],\n",
       "       [0.00081948],\n",
       "       [0.00071708],\n",
       "       [0.00082675],\n",
       "       [0.00067345],\n",
       "       [0.000671  ],\n",
       "       [0.00061831],\n",
       "       [0.00085361],\n",
       "       [0.00075594],\n",
       "       [0.00068979],\n",
       "       [0.0007056 ],\n",
       "       [0.00079394],\n",
       "       [0.00076999],\n",
       "       [0.00077666],\n",
       "       [0.00082155],\n",
       "       [0.00079832],\n",
       "       [0.000627  ],\n",
       "       [0.00067419],\n",
       "       [0.00074078],\n",
       "       [0.00067831],\n",
       "       [0.00065977],\n",
       "       [0.00080023],\n",
       "       [0.00069211],\n",
       "       [0.00064297],\n",
       "       [0.00082693],\n",
       "       [0.00082978],\n",
       "       [0.00070935],\n",
       "       [0.00068075],\n",
       "       [0.00059319],\n",
       "       [0.00063379],\n",
       "       [0.00061633],\n",
       "       [0.00069571],\n",
       "       [0.00073611],\n",
       "       [0.00071703],\n",
       "       [0.00072292],\n",
       "       [0.00072477],\n",
       "       [0.00070824],\n",
       "       [0.00081575],\n",
       "       [0.00093677],\n",
       "       [0.00070811],\n",
       "       [0.00065325],\n",
       "       [0.0007334 ],\n",
       "       [0.00068402],\n",
       "       [0.00084092],\n",
       "       [0.00064419],\n",
       "       [0.00071318],\n",
       "       [0.00067005],\n",
       "       [0.00074634],\n",
       "       [0.00075875],\n",
       "       [0.00075623],\n",
       "       [0.00090756],\n",
       "       [0.00091672],\n",
       "       [0.00075687],\n",
       "       [0.00069434],\n",
       "       [0.00070071],\n",
       "       [0.00070751],\n",
       "       [0.000688  ],\n",
       "       [0.00065852],\n",
       "       [0.00066286],\n",
       "       [0.00068689],\n",
       "       [0.0007241 ],\n",
       "       [0.00071567],\n",
       "       [0.00079837],\n",
       "       [0.00068127],\n",
       "       [0.00071986],\n",
       "       [0.0008055 ],\n",
       "       [0.00064823],\n",
       "       [0.00063473],\n",
       "       [0.00068774],\n",
       "       [0.00070946],\n",
       "       [0.00069193],\n",
       "       [0.00076954],\n",
       "       [0.00093069],\n",
       "       [0.00089339],\n",
       "       [0.00104511],\n",
       "       [0.00093046],\n",
       "       [0.0009366 ],\n",
       "       [0.00089615],\n",
       "       [0.00071907],\n",
       "       [0.00084332],\n",
       "       [0.0008063 ],\n",
       "       [0.00096134],\n",
       "       [0.00085352],\n",
       "       [0.00079692],\n",
       "       [0.00092631],\n",
       "       [0.00084374],\n",
       "       [0.00074993],\n",
       "       [0.00068346],\n",
       "       [0.00080471],\n",
       "       [0.00077728],\n",
       "       [0.00088462],\n",
       "       [0.00094272],\n",
       "       [0.00070794],\n",
       "       [0.00055327],\n",
       "       [0.00060432],\n",
       "       [0.00084307],\n",
       "       [0.00090238],\n",
       "       [0.00069048],\n",
       "       [0.00067308],\n",
       "       [0.0007121 ],\n",
       "       [0.00076395],\n",
       "       [0.0011055 ],\n",
       "       [0.00084325],\n",
       "       [0.00075207],\n",
       "       [0.00086683],\n",
       "       [0.00074026],\n",
       "       [0.00083655],\n",
       "       [0.00082037],\n",
       "       [0.00074001],\n",
       "       [0.00086488],\n",
       "       [0.00072345],\n",
       "       [0.00087396],\n",
       "       [0.00074371],\n",
       "       [0.00088759],\n",
       "       [0.00079734],\n",
       "       [0.0007916 ],\n",
       "       [0.00087462],\n",
       "       [0.00101544],\n",
       "       [0.00091251],\n",
       "       [0.00074454],\n",
       "       [0.00092601],\n",
       "       [0.00088876],\n",
       "       [0.0007614 ],\n",
       "       [0.00085368],\n",
       "       [0.0009213 ],\n",
       "       [0.00103157],\n",
       "       [0.00091102],\n",
       "       [0.00078901],\n",
       "       [0.00104508],\n",
       "       [0.00087269],\n",
       "       [0.00077473],\n",
       "       [0.00074647],\n",
       "       [0.00089669],\n",
       "       [0.00099167],\n",
       "       [0.00058101],\n",
       "       [0.0008893 ],\n",
       "       [0.00081796],\n",
       "       [0.00064173],\n",
       "       [0.00077745],\n",
       "       [0.00086033],\n",
       "       [0.0006711 ],\n",
       "       [0.00066287],\n",
       "       [0.00093023],\n",
       "       [0.000629  ],\n",
       "       [0.00098165],\n",
       "       [0.00089776],\n",
       "       [0.00088481],\n",
       "       [0.00088773],\n",
       "       [0.00072512],\n",
       "       [0.00073651],\n",
       "       [0.00083768],\n",
       "       [0.0007046 ],\n",
       "       [0.00085876],\n",
       "       [0.00087324],\n",
       "       [0.0007999 ],\n",
       "       [0.00083985],\n",
       "       [0.00084633],\n",
       "       [0.00092801],\n",
       "       [0.00065206],\n",
       "       [0.00066664],\n",
       "       [0.00061025],\n",
       "       [0.00070035],\n",
       "       [0.000971  ],\n",
       "       [0.00073137],\n",
       "       [0.00101154],\n",
       "       [0.00087333],\n",
       "       [0.00069314],\n",
       "       [0.00075818],\n",
       "       [0.00085766],\n",
       "       [0.00085503],\n",
       "       [0.00081343],\n",
       "       [0.00068084],\n",
       "       [0.00069949],\n",
       "       [0.00055632],\n",
       "       [0.00097211],\n",
       "       [0.00072084],\n",
       "       [0.00107015],\n",
       "       [0.00099667],\n",
       "       [0.00061001],\n",
       "       [0.00073651],\n",
       "       [0.00070354],\n",
       "       [0.00088513],\n",
       "       [0.00078885],\n",
       "       [0.00068927],\n",
       "       [0.00076076],\n",
       "       [0.00067616],\n",
       "       [0.00056433],\n",
       "       [0.00071572],\n",
       "       [0.00077976],\n",
       "       [0.00079039],\n",
       "       [0.00089118],\n",
       "       [0.00096998],\n",
       "       [0.00076905],\n",
       "       [0.00094566],\n",
       "       [0.00084795],\n",
       "       [0.00059763],\n",
       "       [0.00093277],\n",
       "       [0.00083131],\n",
       "       [0.00069434],\n",
       "       [0.00082454],\n",
       "       [0.00060019],\n",
       "       [0.00063978],\n",
       "       [0.00080202],\n",
       "       [0.0007787 ],\n",
       "       [0.00097199],\n",
       "       [0.00079217],\n",
       "       [0.00063321],\n",
       "       [0.00087449],\n",
       "       [0.00084599],\n",
       "       [0.00105597],\n",
       "       [0.00085872],\n",
       "       [0.00057794],\n",
       "       [0.00079359],\n",
       "       [0.00096878],\n",
       "       [0.00123043],\n",
       "       [0.00106894],\n",
       "       [0.00076341],\n",
       "       [0.00071538],\n",
       "       [0.00099908],\n",
       "       [0.00086534],\n",
       "       [0.00070964],\n",
       "       [0.00068919],\n",
       "       [0.00060135],\n",
       "       [0.00072258],\n",
       "       [0.00101566],\n",
       "       [0.00077373],\n",
       "       [0.00075666],\n",
       "       [0.00099479],\n",
       "       [0.00080891],\n",
       "       [0.00077204],\n",
       "       [0.00102487],\n",
       "       [0.00099695],\n",
       "       [0.00088417],\n",
       "       [0.00064576],\n",
       "       [0.00096405],\n",
       "       [0.00078546],\n",
       "       [0.00076714],\n",
       "       [0.00074721],\n",
       "       [0.00091048],\n",
       "       [0.00066789],\n",
       "       [0.00063433],\n",
       "       [0.00066001],\n",
       "       [0.00071823],\n",
       "       [0.0006132 ],\n",
       "       [0.00092551],\n",
       "       [0.00066295],\n",
       "       [0.00072632],\n",
       "       [0.00066688],\n",
       "       [0.00083223],\n",
       "       [0.00083661],\n",
       "       [0.00103283],\n",
       "       [0.00062752],\n",
       "       [0.00072855],\n",
       "       [0.00090876],\n",
       "       [0.00080476],\n",
       "       [0.00071324],\n",
       "       [0.0005967 ],\n",
       "       [0.00083745],\n",
       "       [0.00084936],\n",
       "       [0.00072932],\n",
       "       [0.00068221],\n",
       "       [0.00073486],\n",
       "       [0.00080263],\n",
       "       [0.00080392],\n",
       "       [0.00080967],\n",
       "       [0.00078911],\n",
       "       [0.00084777],\n",
       "       [0.00062396],\n",
       "       [0.00073859],\n",
       "       [0.00072098],\n",
       "       [0.00089778],\n",
       "       [0.00069339],\n",
       "       [0.00063031],\n",
       "       [0.00059575],\n",
       "       [0.00060571],\n",
       "       [0.00063796],\n",
       "       [0.00067143],\n",
       "       [0.00069048],\n",
       "       [0.00062247],\n",
       "       [0.00065434],\n",
       "       [0.00060621],\n",
       "       [0.00057801],\n",
       "       [0.00066732],\n",
       "       [0.00057499],\n",
       "       [0.00072904],\n",
       "       [0.00066343],\n",
       "       [0.00074062],\n",
       "       [0.00060739],\n",
       "       [0.00071371],\n",
       "       [0.00065006],\n",
       "       [0.00071069],\n",
       "       [0.00057608],\n",
       "       [0.00058311],\n",
       "       [0.00072246],\n",
       "       [0.00066214],\n",
       "       [0.00066959],\n",
       "       [0.00066146],\n",
       "       [0.00062185],\n",
       "       [0.00068343],\n",
       "       [0.00077234],\n",
       "       [0.00074041],\n",
       "       [0.00072228],\n",
       "       [0.00069435],\n",
       "       [0.00069795],\n",
       "       [0.00060694],\n",
       "       [0.0006066 ],\n",
       "       [0.00070382],\n",
       "       [0.00076325],\n",
       "       [0.00066161],\n",
       "       [0.00069891],\n",
       "       [0.00058701],\n",
       "       [0.00065405],\n",
       "       [0.00067145],\n",
       "       [0.00068093],\n",
       "       [0.00064463],\n",
       "       [0.00068886],\n",
       "       [0.00069468],\n",
       "       [0.00077452],\n",
       "       [0.00061858],\n",
       "       [0.00086813],\n",
       "       [0.00066018],\n",
       "       [0.00070604],\n",
       "       [0.00060544],\n",
       "       [0.00074965],\n",
       "       [0.0007445 ],\n",
       "       [0.00070612],\n",
       "       [0.00067863],\n",
       "       [0.00059038],\n",
       "       [0.00069025],\n",
       "       [0.00071279],\n",
       "       [0.00066206],\n",
       "       [0.0006561 ],\n",
       "       [0.0007686 ],\n",
       "       [0.00064556],\n",
       "       [0.00074226],\n",
       "       [0.00071787],\n",
       "       [0.00074918],\n",
       "       [0.00070955],\n",
       "       [0.00062109],\n",
       "       [0.00066592],\n",
       "       [0.00065496],\n",
       "       [0.00054913],\n",
       "       [0.00067082],\n",
       "       [0.00067762],\n",
       "       [0.0006442 ],\n",
       "       [0.00067007],\n",
       "       [0.00077828],\n",
       "       [0.00066385],\n",
       "       [0.00084314],\n",
       "       [0.00075192],\n",
       "       [0.00061681],\n",
       "       [0.00073153],\n",
       "       [0.00064651],\n",
       "       [0.00078939],\n",
       "       [0.00066415],\n",
       "       [0.00071   ],\n",
       "       [0.00075515],\n",
       "       [0.00064084],\n",
       "       [0.00077344],\n",
       "       [0.00068695],\n",
       "       [0.00078355],\n",
       "       [0.00062462],\n",
       "       [0.00072171],\n",
       "       [0.00066404],\n",
       "       [0.00070115],\n",
       "       [0.00067512],\n",
       "       [0.00063526],\n",
       "       [0.00070018],\n",
       "       [0.00068561],\n",
       "       [0.00074672],\n",
       "       [0.00077485],\n",
       "       [0.00067683],\n",
       "       [0.00084412],\n",
       "       [0.00090768],\n",
       "       [0.00067085],\n",
       "       [0.00081952],\n",
       "       [0.00067667],\n",
       "       [0.00088024],\n",
       "       [0.00062903],\n",
       "       [0.00066202],\n",
       "       [0.0006478 ],\n",
       "       [0.00072279],\n",
       "       [0.00076782],\n",
       "       [0.00058698],\n",
       "       [0.00065955],\n",
       "       [0.00073318],\n",
       "       [0.00065247],\n",
       "       [0.00066974],\n",
       "       [0.00075995],\n",
       "       [0.00068327],\n",
       "       [0.00068122],\n",
       "       [0.00064114],\n",
       "       [0.00091802],\n",
       "       [0.00062655],\n",
       "       [0.00085129],\n",
       "       [0.00076359],\n",
       "       [0.00072491],\n",
       "       [0.0008012 ],\n",
       "       [0.00072611],\n",
       "       [0.00070148],\n",
       "       [0.00067767],\n",
       "       [0.00073904],\n",
       "       [0.00071175],\n",
       "       [0.00068718],\n",
       "       [0.00082134],\n",
       "       [0.00061375],\n",
       "       [0.00076572],\n",
       "       [0.0007511 ],\n",
       "       [0.00068057],\n",
       "       [0.00075629],\n",
       "       [0.00067353],\n",
       "       [0.00054435],\n",
       "       [0.00067052],\n",
       "       [0.00077592],\n",
       "       [0.00060628],\n",
       "       [0.00085878],\n",
       "       [0.0005956 ],\n",
       "       [0.00061071],\n",
       "       [0.0007006 ],\n",
       "       [0.00070805],\n",
       "       [0.00075502],\n",
       "       [0.00081439],\n",
       "       [0.00084271],\n",
       "       [0.00066705],\n",
       "       [0.00073038],\n",
       "       [0.00067723],\n",
       "       [0.0008014 ],\n",
       "       [0.00064145],\n",
       "       [0.00073479],\n",
       "       [0.00079442],\n",
       "       [0.00065323],\n",
       "       [0.00084379],\n",
       "       [0.00069668],\n",
       "       [0.00074752],\n",
       "       [0.00092641],\n",
       "       [0.00064536],\n",
       "       [0.0006869 ],\n",
       "       [0.00078743],\n",
       "       [0.00073938],\n",
       "       [0.00069986],\n",
       "       [0.00076367],\n",
       "       [0.00059052],\n",
       "       [0.00067115],\n",
       "       [0.00085103],\n",
       "       [0.00070204],\n",
       "       [0.00071279],\n",
       "       [0.00077696],\n",
       "       [0.00064211],\n",
       "       [0.00056057],\n",
       "       [0.00071384],\n",
       "       [0.00052912],\n",
       "       [0.00065862],\n",
       "       [0.00065727],\n",
       "       [0.00060792],\n",
       "       [0.00061571],\n",
       "       [0.00087519],\n",
       "       [0.00084247],\n",
       "       [0.00070501],\n",
       "       [0.00057257],\n",
       "       [0.00070607],\n",
       "       [0.00067875],\n",
       "       [0.00065363],\n",
       "       [0.0007475 ],\n",
       "       [0.00064781],\n",
       "       [0.00077699],\n",
       "       [0.00079827],\n",
       "       [0.00075917],\n",
       "       [0.00058296],\n",
       "       [0.00082582],\n",
       "       [0.00083929],\n",
       "       [0.000626  ],\n",
       "       [0.00087416],\n",
       "       [0.00080875],\n",
       "       [0.00071477],\n",
       "       [0.00074085],\n",
       "       [0.00064681],\n",
       "       [0.00061917],\n",
       "       [0.00062345],\n",
       "       [0.00067296],\n",
       "       [0.00066569],\n",
       "       [0.00068399],\n",
       "       [0.00061194],\n",
       "       [0.00073329],\n",
       "       [0.00080581],\n",
       "       [0.00068022],\n",
       "       [0.00067799],\n",
       "       [0.00072306],\n",
       "       [0.0005827 ],\n",
       "       [0.00069798],\n",
       "       [0.00056077],\n",
       "       [0.00063912],\n",
       "       [0.00060645],\n",
       "       [0.00096005],\n",
       "       [0.00066876],\n",
       "       [0.00069147],\n",
       "       [0.00067617],\n",
       "       [0.00067318],\n",
       "       [0.00067285],\n",
       "       [0.00065876],\n",
       "       [0.00059574],\n",
       "       [0.00072108],\n",
       "       [0.0006213 ],\n",
       "       [0.00063884],\n",
       "       [0.00065847],\n",
       "       [0.00062079],\n",
       "       [0.00077669],\n",
       "       [0.00066676],\n",
       "       [0.00078258],\n",
       "       [0.00063801],\n",
       "       [0.00065796],\n",
       "       [0.00057317],\n",
       "       [0.00066766],\n",
       "       [0.00070258],\n",
       "       [0.00074475],\n",
       "       [0.00067855],\n",
       "       [0.00065856],\n",
       "       [0.00066643],\n",
       "       [0.0006485 ],\n",
       "       [0.00065335],\n",
       "       [0.00073344],\n",
       "       [0.00075783],\n",
       "       [0.00060127],\n",
       "       [0.00076924],\n",
       "       [0.0006637 ],\n",
       "       [0.00076316],\n",
       "       [0.00070619],\n",
       "       [0.00066355],\n",
       "       [0.0006909 ],\n",
       "       [0.00068843],\n",
       "       [0.00074283],\n",
       "       [0.00064681],\n",
       "       [0.00066215],\n",
       "       [0.00064701],\n",
       "       [0.00066887],\n",
       "       [0.00073654],\n",
       "       [0.00063889],\n",
       "       [0.00072459],\n",
       "       [0.00067891],\n",
       "       [0.00072665],\n",
       "       [0.0007833 ],\n",
       "       [0.00068669],\n",
       "       [0.00071722],\n",
       "       [0.00066709],\n",
       "       [0.00066714],\n",
       "       [0.00068079],\n",
       "       [0.0006896 ],\n",
       "       [0.00061593],\n",
       "       [0.00080834],\n",
       "       [0.00069708],\n",
       "       [0.00067916],\n",
       "       [0.00069612],\n",
       "       [0.00066236],\n",
       "       [0.00069624],\n",
       "       [0.00071279],\n",
       "       [0.00081391],\n",
       "       [0.0007478 ],\n",
       "       [0.00078158],\n",
       "       [0.00082156],\n",
       "       [0.00068395],\n",
       "       [0.0008141 ],\n",
       "       [0.00072644],\n",
       "       [0.00061805],\n",
       "       [0.00059877],\n",
       "       [0.00054837],\n",
       "       [0.00068831],\n",
       "       [0.00080549],\n",
       "       [0.00070666],\n",
       "       [0.00068583],\n",
       "       [0.00071052],\n",
       "       [0.00061821],\n",
       "       [0.00062656],\n",
       "       [0.00064015]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadir_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b33cfd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 104, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._tcav_acts.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89439570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03297416],\n",
       "       [ 0.33101214],\n",
       "       [-0.11765189],\n",
       "       [-0.04690461],\n",
       "       [ 0.03210919],\n",
       "       [-0.04460833],\n",
       "       [-0.02226003],\n",
       "       [-0.04631099],\n",
       "       [ 0.00991599],\n",
       "       [-0.17100279],\n",
       "       [-0.05036304],\n",
       "       [-0.13745825],\n",
       "       [ 0.00794413],\n",
       "       [ 0.02099918],\n",
       "       [-0.00250691],\n",
       "       [ 0.22482662],\n",
       "       [ 0.00728835],\n",
       "       [-0.00522326],\n",
       "       [-0.0212866 ],\n",
       "       [-0.00739012],\n",
       "       [ 0.01401818],\n",
       "       [ 0.10765859],\n",
       "       [-0.07550145],\n",
       "       [ 0.07931605],\n",
       "       [ 0.01503608],\n",
       "       [ 0.07150803],\n",
       "       [-0.07139318],\n",
       "       [-0.05169635],\n",
       "       [-0.00820409],\n",
       "       [ 0.12700651],\n",
       "       [-0.0331678 ],\n",
       "       [ 0.09080516],\n",
       "       [-0.02124833],\n",
       "       [-0.06124515],\n",
       "       [ 0.00797757],\n",
       "       [-0.05143098],\n",
       "       [ 0.16436235],\n",
       "       [-0.05247383],\n",
       "       [-0.04136527],\n",
       "       [-0.16268531],\n",
       "       [ 0.13618894],\n",
       "       [ 0.01025466],\n",
       "       [-0.03644122],\n",
       "       [-0.14382278],\n",
       "       [ 0.00599246],\n",
       "       [-0.01748055],\n",
       "       [-0.00630998],\n",
       "       [ 0.20539224],\n",
       "       [-0.03287872],\n",
       "       [ 0.036723  ],\n",
       "       [-0.05833863],\n",
       "       [-0.03747916],\n",
       "       [-0.00878221],\n",
       "       [ 0.12890621],\n",
       "       [-0.02163372],\n",
       "       [-0.20454478],\n",
       "       [ 0.03924909],\n",
       "       [ 0.04133821],\n",
       "       [-0.02319168],\n",
       "       [-0.00170965],\n",
       "       [ 0.03758753],\n",
       "       [-0.02763373],\n",
       "       [ 0.01906037],\n",
       "       [-0.05905715],\n",
       "       [ 0.03186388],\n",
       "       [ 0.00294003],\n",
       "       [-0.00060991],\n",
       "       [-0.01418417],\n",
       "       [-0.00590231],\n",
       "       [ 0.0424269 ],\n",
       "       [ 0.00447929],\n",
       "       [-0.02947087],\n",
       "       [-0.04863318],\n",
       "       [ 0.04085393],\n",
       "       [ 0.02838258],\n",
       "       [ 0.04209051],\n",
       "       [-0.00457385],\n",
       "       [-0.13150926],\n",
       "       [-0.00577172],\n",
       "       [-0.00353658],\n",
       "       [ 0.08236669],\n",
       "       [-0.02826352],\n",
       "       [ 0.03416232],\n",
       "       [-0.01143096],\n",
       "       [ 0.11168435],\n",
       "       [-0.24496331],\n",
       "       [ 0.22850581],\n",
       "       [ 0.0300889 ],\n",
       "       [-0.01075186],\n",
       "       [ 0.06837032],\n",
       "       [-0.08764888],\n",
       "       [-0.05468606],\n",
       "       [-0.09736672],\n",
       "       [ 0.18905171],\n",
       "       [-0.0171911 ],\n",
       "       [-0.12026018],\n",
       "       [ 0.05883395],\n",
       "       [ 0.00059828],\n",
       "       [ 0.02811315],\n",
       "       [-0.00107304],\n",
       "       [-0.09493515],\n",
       "       [-0.11553408],\n",
       "       [ 0.04303909],\n",
       "       [-0.11260903],\n",
       "       [ 0.00313145],\n",
       "       [ 0.00475179],\n",
       "       [ 0.02190781],\n",
       "       [ 0.12957538],\n",
       "       [ 0.17426897],\n",
       "       [ 0.03146664],\n",
       "       [ 0.02945446],\n",
       "       [ 0.04265524],\n",
       "       [-0.05115993],\n",
       "       [ 0.09253469],\n",
       "       [ 0.01927328],\n",
       "       [-0.00351723],\n",
       "       [ 0.0313013 ],\n",
       "       [ 0.0596894 ],\n",
       "       [-0.11893375],\n",
       "       [-0.15460179],\n",
       "       [ 0.00355625],\n",
       "       [-0.09144495],\n",
       "       [ 0.03379491],\n",
       "       [ 0.00451618],\n",
       "       [-0.0042001 ],\n",
       "       [-0.1079198 ],\n",
       "       [-0.24281293],\n",
       "       [ 0.11828798]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_cav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53458e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weaver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
